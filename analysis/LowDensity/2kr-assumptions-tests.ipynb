{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indoor-tonight",
   "metadata": {},
   "source": [
    "# 2kr Assumptions Tests (Low Density Scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opening-maker",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "%matplotlib inline\n",
    "\n",
    "def parse_if_number(s):\n",
    "    try: return float(s)\n",
    "    except: return True if s==\"true\" else False if s==\"false\" else s if s else None\n",
    "\n",
    "def parse_ndarray(s):\n",
    "    return np.fromstring(s, sep=' ') if s else None\n",
    "\n",
    "def get_file_name(name):\n",
    "    return name.replace(':', '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-scanning",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "august-english",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputFile = 'data.csv'\n",
    "repetitionsCount = -1 # -1 = auto-detect\n",
    "factors = ['T', 'm', 'D', '']\n",
    "\n",
    "# Fitting\n",
    "distsFit = ['norm'] # Distributions to fit\n",
    "distsParams = [()] # Distributions params\n",
    "outlierStddevDistance = 3 # Outliers identification\n",
    "\n",
    "# Plots\n",
    "histBinNum = 30 # Histograms\n",
    "histCenter = True # Center distribution\n",
    "plotSize = (10, 10)\n",
    "plotStyle = 'seaborn-whitegrid'\n",
    "scatterShowLines = False\n",
    "# Save\n",
    "saveFigures = False\n",
    "\n",
    "# Filter scalars\n",
    "scalarsFilter = ['Floorplan.userCount', 'Floorplan.coveredUsers:sum', 'Floorplan.collisions:sum', 'Floorplan.msgsPerSlot:sum']\n",
    "# Filter vectors\n",
    "vectorsFilter = ['Floorplan.coveredUsers:vector']\n",
    "# Percentiles\n",
    "percentiles = [0.25, 0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "\n",
    "# Residuals to compute\n",
    "residualNames = [\n",
    "    ('coveredUsersPercent', 'percentage of covered users (residuals)'),\n",
    "    ('collisions', 'total number of collisions (residuals)'),\n",
    "    ('msgsPerSlot', 'total number of messages sent (residuals)'),\n",
    "]\n",
    "\n",
    "# Transformations\n",
    "transformations = [\n",
    "]\n",
    "\n",
    "intPercentiles = [int(i*100) for i in percentiles]\n",
    "vecPerfIndexes = []\n",
    "for intPercentile in intPercentiles:\n",
    "    vecPerfIndexes.append(('broadcastTime' + str(intPercentile), 'Broadcast time needed to reach the ' + str(intPercentile) + 'th percentile of the coverage'))\n",
    "for i, d in vecPerfIndexes:\n",
    "    residualNames.append((i, d + ' (residuals)'))\n",
    "    transformations.append((i, lambda x: math.log(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-dealing",
   "metadata": {},
   "source": [
    "## Load scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "supreme-harassment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('exported_data/' + inputFile, converters = {\n",
    "    'attrvalue': parse_if_number,\n",
    "    'binedges': parse_ndarray,\n",
    "    'binvalues': parse_ndarray,\n",
    "    'vectime': parse_ndarray,\n",
    "    'vecvalue': parse_ndarray,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sealed-triangle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetitions: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>div.output_scroll { height: auto; max-height: 48em; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if repetitionsCount <= 0: # auto-detect\n",
    "    repetitionsCount = int(df[df.attrname == 'repetition']['attrvalue'].max()) + 1\n",
    "print('Repetitions:', repetitionsCount)\n",
    "\n",
    "# Computed\n",
    "factorsCount = len(factors)\n",
    "configsCount = 2**factorsCount\n",
    "totalSims = configsCount*repetitionsCount\n",
    "\n",
    "# Scatter plot whitelists\n",
    "configsShown = range(0, configsCount)\n",
    "repetitionsShown = range(0, repetitionsCount)\n",
    "\n",
    "\n",
    "display(HTML(\"<style>div.output_scroll { height: auto; max-height: 48em; }</style>\"))\n",
    "pd.set_option('display.max_rows', totalSims)\n",
    "if saveFigures:\n",
    "    os.makedirs('figures', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "later-magazine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e2341eb57322>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mscalars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscalars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombine_first\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscalars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mscalars_wide\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscalars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'run'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'qname'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mscalars_wide\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfactors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'repetition'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscalars_wide\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36msort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   5437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5439\u001b[1;33m             \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5441\u001b[0m             \u001b[1;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   5437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5439\u001b[1;33m             \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5441\u001b[0m             \u001b[1;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1681\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1682\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1683\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1685\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "scalars = df[(df.type == 'scalar') | ((df.type == 'itervar') & (df.attrname != 'TO')) | ((df.type == 'param') & (df.attrname == 'Floorplan.userCount')) | ((df.type == 'runattr') & (df.attrname == 'repetition'))]\n",
    "scalars = scalars.assign(qname = scalars.attrname.combine_first(scalars.module + '.' + scalars.name))\n",
    "for index, row in scalars[scalars.type == 'itervar'].iterrows():\n",
    "    val = scalars.loc[index, 'attrvalue']\n",
    "    if isinstance(val, str)  and not all(c.isdigit() for c in val):\n",
    "        scalars.loc[index, 'attrvalue'] = eval(val)\n",
    "scalars.value = scalars.value.combine_first(scalars.attrvalue.astype('float64'))\n",
    "scalars_wide = scalars.pivot_table(index=['run'], columns='qname', values='value')\n",
    "scalars_wide.sort_values([*factors, 'repetition'], inplace=True)\n",
    "count = 0\n",
    "for index in scalars_wide.index:\n",
    "    config = count // repetitionsCount\n",
    "    scalars_wide.loc[index, 'config'] = config\n",
    "    count += 1\n",
    "scalars_wide = scalars_wide[['config', 'repetition', *factors, *scalarsFilter]]\n",
    "\n",
    "# coverage\n",
    "scalars_wide['coveredUsersPercent'] = scalars_wide['Floorplan.coveredUsers:sum'] / (scalars_wide['Floorplan.userCount'] - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-magnet",
   "metadata": {},
   "source": [
    "## Load vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = df[df.type == 'vector']\n",
    "vectors = vectors.assign(qname = vectors.module + '.' + vectors.name)\n",
    "for index in scalars_wide.index:\n",
    "    r = index\n",
    "    cfg = scalars_wide.loc[index, 'config']\n",
    "    rep = scalars_wide.loc[index, 'repetition']\n",
    "    vectors.loc[vectors.run == r, 'config'] = cfg\n",
    "    vectors.loc[vectors.run == r, 'repetition'] = rep\n",
    "vectors = vectors[vectors.qname.isin(vectorsFilter)]\n",
    "vectors.sort_values(['config', 'repetition', 'qname'], inplace=True)\n",
    "vectors = vectors[['config', 'repetition', 'qname', 'vectime', 'vecvalue']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-eight",
   "metadata": {},
   "source": [
    "## Compute scalars from vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentile(percentile, vectime, vecvalue, totalvalue):\n",
    "    tofind = percentile * totalvalue\n",
    "    idx = 0\n",
    "    csum = vecvalue.cumsum()\n",
    "    for value in csum:\n",
    "        if value >= tofind:\n",
    "            return vectime[idx]\n",
    "        idx += 1\n",
    "    return math.inf\n",
    "\n",
    "for index, row in vectors.iterrows():\n",
    "    for vecPerf, percentile in zip(vecPerfIndexes, percentiles):\n",
    "        vecPerfIndex = vecPerf[0]\n",
    "        cfg = row['config']\n",
    "        rep = row['repetition']\n",
    "        if vecPerfIndex.startswith('broadcastTime'):\n",
    "            total = scalars_wide[(scalars_wide['config'] == cfg) & (scalars_wide['repetition'] == rep)]['Floorplan.userCount'].values[0] - 1\n",
    "        else:\n",
    "            raise Exception('Need to specify total for ' + vecPerfIndex + '. (coding required)')\n",
    "        value = get_percentile(percentile, row['vectime'], row['vecvalue'], total)\n",
    "        scalars_wide.loc[(scalars_wide['config'] == cfg) & (scalars_wide['repetition'] == rep), vecPerfIndex] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-discipline",
   "metadata": {},
   "source": [
    "## Apply transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, transform in transformations:\n",
    "    scalars_wide[col] = scalars_wide[col].map(transform, 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-antigua",
   "metadata": {},
   "source": [
    "## Compute residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-filling",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# coverage\n",
    "scalars_wide['coveredUsersPercentMean'] = scalars_wide.groupby(factors)['coveredUsersPercent'].transform('mean')\n",
    "scalars_wide['coveredUsersPercentResidual'] = scalars_wide['coveredUsersPercent'] - scalars_wide['coveredUsersPercentMean']\n",
    "\n",
    "# collisions\n",
    "scalars_wide['collisionsMean'] = scalars_wide.groupby(factors)['Floorplan.collisions:sum'].transform('mean')\n",
    "scalars_wide['collisionsResidual'] = scalars_wide['Floorplan.collisions:sum'] - scalars_wide['collisionsMean']\n",
    "\n",
    "# msgsPerSlot\n",
    "scalars_wide['msgsPerSlotMean'] = scalars_wide.groupby(factors)['Floorplan.msgsPerSlot:sum'].transform('mean')\n",
    "scalars_wide['msgsPerSlotResidual'] = scalars_wide['Floorplan.msgsPerSlot:sum'] - scalars_wide['msgsPerSlotMean']\n",
    "\n",
    "# vectors\n",
    "skipped = []\n",
    "for vecPerfIndex, _ in vecPerfIndexes:\n",
    "    mean = scalars_wide.groupby(factors)[vecPerfIndex].transform('mean')\n",
    "    nextVect = False\n",
    "    for value in mean.values:\n",
    "        if math.isinf(value):\n",
    "            skipped.append(vecPerfIndex)\n",
    "            nextVect = True\n",
    "            continue\n",
    "    if nextVect:\n",
    "        continue\n",
    "    scalars_wide[vecPerfIndex + 'Mean'] = mean\n",
    "    scalars_wide[vecPerfIndex + 'Residual'] = scalars_wide[vecPerfIndex] - scalars_wide[vecPerfIndex + 'Mean']\n",
    "for i, d in vecPerfIndexes:\n",
    "    if i not in skipped:\n",
    "        continue\n",
    "    print(i + ' skipped due to infinite values in observations')\n",
    "    residualNames.remove((i, d + ' (residuals)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-phone",
   "metadata": {},
   "source": [
    "## Residual distributions (histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-bacon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for varname, vardesc in residualNames:\n",
    "    plt.figure(figsize=plotSize)\n",
    "    plt.style.use(plotStyle)\n",
    "    minval = scalars_wide[varname + 'Residual'].min()\n",
    "    maxval = scalars_wide[varname + 'Residual'].max()\n",
    "    if histCenter:\n",
    "        limit = max(abs(minval), abs(maxval))\n",
    "        minval = -limit\n",
    "        maxval = limit\n",
    "    plt.hist(scalars_wide[varname + 'Residual'].values.tolist(), bins=np.linspace(minval, maxval, histBinNum))\n",
    "    plt.title('Histogram for the ' + vardesc)\n",
    "    if saveFigures:\n",
    "        fig = plt.gcf()\n",
    "        fig.savefig('figures/' + get_file_name(varname) + '-hist.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-jesus",
   "metadata": {},
   "source": [
    "### Notes on distributions\n",
    "\n",
    "We can see from histograms that, for all indexes except the percentage of covered users, the distribution of the residuals seems normal. The percentage of covered user has a tail on the left."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-gospel",
   "metadata": {},
   "source": [
    "## Distribution fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-kingdom",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for distribution, params in zip(distsFit, distsParams):\n",
    "    print('Trying to fit to a', distribution + ('({})'.format(', '.join(map(str, params))) if len(params) > 0 else ''), 'distribution:')\n",
    "    for varname, vardesc in residualNames:\n",
    "        plt.figure(figsize=plotSize)\n",
    "        plt.style.use(plotStyle)\n",
    "        residuals = scalars_wide[varname + 'Residual'].values.tolist()\n",
    "        result, line = stats.probplot(residuals, dist=distribution, sparams=params, plot=plt, rvalue=True)\n",
    "        #osm, _ = result\n",
    "        #slope, intercept, _ = line\n",
    "        plt.title(\"QQ plot for the \" + vardesc)\n",
    "        plt.xlabel(distribution + \" distribution\")\n",
    "        if saveFigures:\n",
    "            fig = plt.gcf()\n",
    "            fig.savefig('figures/' + get_file_name(varname) + '-' + distribution + '-fit.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-separation",
   "metadata": {},
   "source": [
    "### Notes on QQ plots\n",
    "\n",
    "For all the indexes, except the percentage of covered users, we get \"good\" QQ-plots that signal a normal distribution of the residuals. The lowest R^2 index is given by the residuals of the total number of messages sent (R^2 = 0.9322). We get this result mainly due to one outlier on the right.\n",
    "\n",
    "As in the high density scenario the percentage of covered users will not be studied in the continue of this experiments, because it is still perfect in all the cases. There will be a new different study for this index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-migration",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-entry",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for varname, vardesc in residualNames:\n",
    "    print('Outliers for the ' + vardesc)\n",
    "    stddev = scalars_wide[varname + 'Residual'].std()\n",
    "    limit = outlierStddevDistance*stddev\n",
    "    print('total mean:', scalars_wide[varname + 'Mean'].mean())\n",
    "    print('stddev:', stddev)\n",
    "    print(str(outlierStddevDistance) + '*stddev:', limit)\n",
    "    outliers = scalars_wide[np.abs(scalars_wide[varname + 'Residual']) > limit]\n",
    "    display(outliers[['config', 'repetition', *factors, varname + 'Residual', varname + 'Mean']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-aurora",
   "metadata": {},
   "source": [
    "## Independency test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-restriction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(scalars_wide.loc[(scalars_wide.repetition == 0) & (scalars_wide.config.isin(configsShown))][['config', *factors]])\n",
    "for varname, vardesc in residualNames:\n",
    "    y = []\n",
    "    x = []\n",
    "    for config in range(0, configsCount):\n",
    "        if config not in configsShown:\n",
    "            continue\n",
    "        x.append([config] * len(repetitionsShown))\n",
    "        y.append(scalars_wide.loc[(scalars_wide.config == config) & (scalars_wide.repetition.isin(repetitionsShown))][varname + 'Residual'].values.tolist())\n",
    "    plt.figure(figsize=plotSize)\n",
    "    plt.style.use(plotStyle)\n",
    "    plt.plot(x, y, 'o' + ('-' if scatterShowLines else ''))\n",
    "    plt.title(\"Test independency for the \" + vardesc)\n",
    "    plt.xlabel(\"Config number\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    if saveFigures:\n",
    "        fig = plt.gcf()\n",
    "        fig.savefig('figures/' + get_file_name(varname) + '-independency.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-clock",
   "metadata": {},
   "source": [
    "### Notes on indipendency test\n",
    "\n",
    "No trend is visible. We expected this result as there is no suspect of dependency between experiments by the way we have conducted the experiments.\n",
    "\n",
    "(percentage of covered users ignored)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-going",
   "metadata": {},
   "source": [
    "## Finite variance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-valentine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for varname, vardesc in residualNames:\n",
    "    y = []\n",
    "    x = []\n",
    "    scalars_wide.sort_values([varname + 'Mean', 'repetition'], inplace=True)\n",
    "    for _, row in scalars_wide.iterrows():\n",
    "        config = row['config']\n",
    "        if config not in configsShown:\n",
    "            continue\n",
    "        x.append(scalars_wide.loc[(scalars_wide.config == config) & (scalars_wide.repetition.isin(repetitionsShown))][varname + 'Mean'].values.tolist())\n",
    "        y.append(scalars_wide.loc[(scalars_wide.config == config) & (scalars_wide.repetition.isin(repetitionsShown))][varname + 'Residual'].values.tolist())\n",
    "    plt.figure(figsize=plotSize)\n",
    "    plt.style.use(plotStyle)\n",
    "    plt.plot(x, y, 'o' + ('-' if scatterShowLines else ''))\n",
    "    plt.title(\"Test finite variance for the \" + vardesc)\n",
    "    plt.xlabel(\"Avg predicted response\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    if saveFigures:\n",
    "        fig = plt.gcf()\n",
    "        fig.savefig('figures/' + get_file_name(varname) + '-variance.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-andrew",
   "metadata": {},
   "source": [
    "### Notes in finite variance test\n",
    "\n",
    "We have an increasing step on left of the collision plot and a decreasing step on the right of the message plot, but they are only steps, there isn't a trend in the residuals. As in the high density scenario, for the broadcast time we applied a logarithmic transformation of the predicted variable.\n",
    "\n",
    "(percentage of covered users ignored)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
